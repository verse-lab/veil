#!/usr/bin/env python3
"""
Parse Firefox Profiler JSON files generated by Lean's trace.profiler.

Usage:
    ./scripts/parse-profile.py <profile.json> [--filter veil.perf]
    ./scripts/parse-profile.py <profile.json> -f veil.perf.tactic -f veil.perf.elaborator  # Multiple filters (additive)
    ./scripts/parse-profile.py <profile.json> --tree
    ./scripts/parse-profile.py <profile.json> --strings
    ./scripts/parse-profile.py *.json  # Aggregate multiple profiles

The Firefox Profiler format uses stack sampling:
- stringArray: Array of all strings (labels, function names, etc.)
- funcTable.name: Function name indices into stringArray
- stackTable: Stack frames forming a tree (frame, prefix)
- samples: Stack samples with timing (stack index, time, weight)

See: https://github.com/firefox-devtools/profiler/blob/main/docs-developer/gecko-profile-format.md
"""

import json
import sys
import argparse
from collections import defaultdict


def load_profile(path: str) -> dict:
    """Load a Firefox Profiler JSON file."""
    with open(path, 'r') as f:
        return json.load(f)


def build_stack_tree(thread: dict) -> dict:
    """Build a tree structure from stackTable.

    Returns dict mapping stack_idx -> (func_name, parent_stack_idx)
    """
    strings = thread.get('stringArray', [])
    func_table = thread.get('funcTable', {})
    func_names = func_table.get('name', [])
    frame_table = thread.get('frameTable', {})
    frame_funcs = frame_table.get('func', [])
    stack_table = thread.get('stackTable', {})
    stack_frames = stack_table.get('frame', [])
    stack_prefixes = stack_table.get('prefix', [])

    def get_func_name(stack_idx):
        if stack_idx is None or stack_idx >= len(stack_frames):
            return None
        frame_idx = stack_frames[stack_idx]
        if frame_idx >= len(frame_funcs):
            return None
        func_idx = frame_funcs[frame_idx]
        if func_idx >= len(func_names):
            return None
        name_idx = func_names[func_idx]
        if name_idx >= len(strings):
            return f"<{name_idx}>"
        return strings[name_idx]

    tree = {}
    for i in range(len(stack_frames)):
        name = get_func_name(i)
        prefix = stack_prefixes[i] if i < len(stack_prefixes) else None
        tree[i] = (name, prefix)

    return tree


def get_stack_trace(tree: dict, stack_idx: int) -> list:
    """Get full stack trace from leaf to root."""
    trace = []
    while stack_idx is not None:
        if stack_idx not in tree:
            break
        name, parent = tree[stack_idx]
        if name:
            trace.append(name)
        stack_idx = parent
    return trace  # leaf to root order


def matches_filter(func_name: str, filter_prefixes: list = None, use_default: bool = False) -> bool:
    """Check if a function name matches the filter criteria.

    When multiple filter_prefixes are provided, they are additive (OR logic).
    """
    if use_default:
        # Default: match veil or smt
        return "veil" in func_name or "smt" in func_name
    if filter_prefixes:
        return any(prefix in func_name for prefix in filter_prefixes)
    return True


def analyze_samples(thread: dict, filter_prefixes: list = None, use_default_filter: bool = False) -> dict:
    """Analyze stack samples to compute time per function.

    Returns dict: func_name -> {"self_time": ms, "total_time": ms, "count": n}
    """
    tree = build_stack_tree(thread)
    samples = thread.get('samples', {})
    stacks = samples.get('stack', [])
    times = samples.get('time', [])
    weights = samples.get('weight', [])

    stats = defaultdict(lambda: {"self_time": 0, "total_time": 0, "count": 0})

    for i, stack_idx in enumerate(stacks):
        if stack_idx is None:
            continue

        weight = weights[i] if i < len(weights) else 1
        trace = get_stack_trace(tree, stack_idx)

        if not trace:
            continue

        # Apply filter if specified
        if filter_prefixes or use_default_filter:
            trace = [f for f in trace if matches_filter(f, filter_prefixes, use_default_filter)]
            if not trace:
                continue

        # Self time goes to the leaf (first in trace)
        leaf = trace[0]
        stats[leaf]["self_time"] += weight
        stats[leaf]["count"] += 1

        # Total time goes to all functions in stack
        seen = set()
        for func in trace:
            if func not in seen:
                stats[func]["total_time"] += weight
                seen.add(func)

    return dict(stats)


def get_total_cpu_time(stats: dict) -> float:
    """Get total CPU time from stats (sum of all self_time values in ms)."""
    return sum(data["self_time"] for data in stats.values())


def print_summary(stats: dict, sort_by: str = "total_time", limit: int = 0):
    """Print function timing summary."""
    if not stats:
        print("No matching functions found.")
        return

    sorted_stats = sorted(stats.items(), key=lambda x: x[1][sort_by], reverse=True)

    print(f"\n{'Function':<70} {'Self (ms)':>10} {'Total (ms)':>10} {'Count':>8}")
    print("-" * 100)

    entries = sorted_stats if limit <= 0 else sorted_stats[:limit]
    for name, data in entries:
        # Truncate long names
        display_name = name if len(name) <= 68 else name[:65] + "..."
        print(f"{display_name:<70} {data['self_time']:>10.1f} {data['total_time']:>10.1f} {data['count']:>8}")


def print_tree_view(thread: dict, filter_prefixes: list = None):
    """Print a tree view of the call hierarchy."""
    tree = build_stack_tree(thread)
    samples = thread.get('samples', {})
    stacks = samples.get('stack', [])
    weights = samples.get('weight', [])

    # Build call tree with timing
    call_tree = defaultdict(lambda: {"children": defaultdict(int), "self_time": 0})

    for i, stack_idx in enumerate(stacks):
        if stack_idx is None:
            continue

        weight = weights[i] if i < len(weights) else 1
        trace = get_stack_trace(tree, stack_idx)

        if filter_prefixes:
            # Only show filtered functions but keep hierarchy
            trace = [f for f in trace if any(prefix in f for prefix in filter_prefixes)]

        if not trace:
            continue

        # Record self time at leaf
        call_tree[trace[0]]["self_time"] += weight

        # Record parent-child relationships (trace is leaf->root)
        for j in range(len(trace) - 1):
            child = trace[j]
            parent = trace[j + 1]
            call_tree[parent]["children"][child] += weight

    # Print tree starting from roots (functions with no callers in filtered set)
    all_children = set()
    for data in call_tree.values():
        all_children.update(data["children"].keys())

    roots = [f for f in call_tree.keys() if f not in all_children]

    def print_node(name, indent=0, visited=None):
        if visited is None:
            visited = set()
        if name in visited:
            return
        visited.add(name)

        data = call_tree[name]
        total = data["self_time"] + sum(data["children"].values())
        prefix = "  " * indent
        display_name = name if len(name) + indent * 2 <= 68 else name[:65 - indent * 2] + "..."
        print(f"{prefix}{display_name:<{70-indent*2}} {total:>10.1f}")

        # Sort children by time
        sorted_children = sorted(data["children"].items(), key=lambda x: x[1], reverse=True)
        for child, _ in sorted_children[:10]:  # Limit children shown
            print_node(child, indent + 1, visited.copy())

    print(f"\n{'Call Tree':<70} {'Time (ms)':>10}")
    print("-" * 82)

    sorted_roots = sorted(roots, key=lambda r: call_tree[r]["self_time"] + sum(call_tree[r]["children"].values()), reverse=True)
    for root in sorted_roots[:10]:
        print_node(root)
        print()


def merge_stats(all_stats: list) -> dict:
    """Merge stats from multiple threads."""
    merged = defaultdict(lambda: {"self_time": 0, "total_time": 0, "count": 0})
    for stats in all_stats:
        for name, data in stats.items():
            merged[name]["self_time"] += data["self_time"]
            merged[name]["total_time"] += data["total_time"]
            merged[name]["count"] += data["count"]
    return dict(merged)


def print_thread_summary(profile: dict, filter_prefixes: list = None):
    """Print summary of all threads with sample counts and matching strings."""
    threads = profile.get('threads', [])
    print(f"\nThreads: {len(threads)}")
    for i, thread in enumerate(threads):
        name = thread.get('name', f'Thread {i}')
        samples = thread.get('samples', {})
        sample_count = len(samples.get('stack', []))
        strings = thread.get('stringArray', [])
        if filter_prefixes:
            matching = [s for s in strings if any(prefix in str(s).lower() for prefix in filter_prefixes)]
        else:
            matching = [s for s in strings if 'veil' in str(s).lower() or 'smt' in str(s).lower()]
        print(f"  [{i}] {name}: {sample_count} samples, {len(matching)} matching strings")


def analyze_single_profile(profile: dict, filter_prefixes: list = None, use_default_filter: bool = False) -> dict:
    """Analyze a single profile and return merged stats from all threads."""
    threads = profile.get('threads', [])
    all_stats = []
    for thread in threads:
        stats = analyze_samples(thread, filter_prefixes, use_default_filter)
        all_stats.append(stats)
    return merge_stats(all_stats)


def main():
    parser = argparse.ArgumentParser(
        description='Parse Firefox Profiler JSON files from Lean profiler'
    )
    parser.add_argument('profiles', nargs='+', help='Path to profile.json file(s)')
    parser.add_argument('--filter', '-f', action='append', default=None,
                        help='Filter functions by prefix (e.g., "veil.perf"). Can be specified multiple times for additive filtering.')
    parser.add_argument('--exclude', '-e', default=None,
                        help='Exclude functions matching pattern (e.g., "veil.perf.discharger")')
    parser.add_argument('--tree', '-t', action='store_true',
                        help='Show hierarchical call tree view')
    parser.add_argument('--strings', '-s', action='store_true',
                        help='List all Veil-related strings')
    parser.add_argument('--all', '-a', action='store_true',
                        help='Show all functions (not just Veil)')
    parser.add_argument('--threads', action='store_true',
                        help='Show summary of all threads')
    parser.add_argument('--thread', type=int, default=None,
                        help='Analyze specific thread by index (default: all threads)')
    parser.add_argument('--total-only', action='store_true',
                        help='Output only total CPU time in ms (for scripting)')
    parser.add_argument('--limit', '-l', type=int, default=0,
                        help='Maximum number of functions to display (default: no limit)')
    args = parser.parse_args()

    # Default filter to veil/smt unless --all specified
    # Use None to indicate "veil or smt" default filtering
    filter_prefixes = args.filter  # Now a list or None
    use_default_filter = filter_prefixes is None and not args.all

    # Handle multiple profiles (aggregate mode)
    if len(args.profiles) > 1:
        if not args.total_only:
            print(f"Aggregating {len(args.profiles)} profiles")
        all_stats = []
        for path in args.profiles:
            try:
                profile = load_profile(path)
                stats = analyze_single_profile(profile, filter_prefixes, use_default_filter)
                all_stats.append(stats)
            except Exception as e:
                if not args.total_only:
                    print(f"  Warning: Failed to load {path}: {e}")
        if not all_stats:
            if not args.total_only:
                print("No valid profiles found.")
            return
        merged = merge_stats(all_stats)
        # Apply exclusion filter
        if args.exclude:
            merged = {k: v for k, v in merged.items() if args.exclude not in k}
        if args.total_only:
            print(f"{get_total_cpu_time(merged):.1f}")
        else:
            print_summary(merged, limit=args.limit)
        return

    # Single profile mode
    profile = load_profile(args.profiles[0])

    # Handle --total-only for single profile
    if args.total_only:
        stats = analyze_single_profile(profile, filter_prefixes, use_default_filter)
        if args.exclude:
            stats = {k: v for k, v in stats.items() if args.exclude not in k}
        print(f"{get_total_cpu_time(stats):.1f}")
        return

    print(f"Profile: {args.profiles[0]}")
    meta = profile.get('meta', {})
    print(f"Version: {meta.get('version', 'unknown')}, Interval: {meta.get('interval', 'unknown')}ms")

    if args.threads:
        print_thread_summary(profile, filter_prefixes)
        return

    if args.strings:
        threads = profile.get('threads', [])
        all_strings = set()
        for thread in threads:
            strings = thread.get('stringArray', [])
            all_strings.update(strings)
        matching_strings = sorted([s for s in all_strings if 'veil' in str(s).lower() or 'smt' in str(s).lower()])
        print(f"\nVeil/SMT-related strings ({len(matching_strings)}):")
        for s in matching_strings:
            print(f"  {s}")
        return

    # Analyze threads
    threads = profile.get('threads', [])
    if not threads:
        print("No threads found in profile.")
        return

    if args.thread is not None:
        # Analyze single thread
        if args.thread >= len(threads):
            print(f"Thread index {args.thread} out of range (0-{len(threads)-1})")
            return
        thread = threads[args.thread]
        thread_name = thread.get('name', f'Thread {args.thread}')
        print(f"Analyzing thread [{args.thread}]: {thread_name}")

        if args.tree:
            print_tree_view(thread, filter_prefixes)
        else:
            stats = analyze_samples(thread, filter_prefixes, use_default_filter)
            # Apply exclusion filter
            if args.exclude:
                stats = {k: v for k, v in stats.items() if args.exclude not in k}
            print_summary(stats, limit=args.limit)
    else:
        # Analyze all threads combined
        print(f"Analyzing all {len(threads)} threads combined")

        if args.tree:
            # Tree view doesn't merge well, just show main thread
            print("(Tree view shows main thread only)")
            print_tree_view(threads[0], filter_prefixes)
        else:
            all_stats = []
            for thread in threads:
                stats = analyze_samples(thread, filter_prefixes, use_default_filter)
                all_stats.append(stats)
            merged = merge_stats(all_stats)
            # Apply exclusion filter
            if args.exclude:
                merged = {k: v for k, v in merged.items() if args.exclude not in k}
            print_summary(merged, limit=args.limit)


if __name__ == '__main__':
    main()
